# -*- coding: utf-8 -*-
"""PATRICK_KARIUKI_CS-DA02-25041_CyberShujaa_Deeplearning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-Rt6hRnY0O_sC6Nb6QsBvr00AosB-Yx

NAME: PATRICK KIMATHI KARIUKI
STUDENT ID: CS-DA02-25041
DATE: 22,  NOVEMBERR 2025
TASK: Assignment 10: Deep Learning
Description :  Apply your understanding of Artificial Neural Networks and
TensorFlow/Keras to build, train, evaluate, and document an image classification model using the MNIST dataset.

# Import the relevant libraries and modules
"""

#import the relevant libraries and modules

#numpy
import numpy as np
#matplotlib
import matplotlib.pyplot as plt
#seaborn
import seaborn as sns
# tensorflow
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
#sklearn
from sklearn.metrics import confusion_matrix, classification_report

"""# Load the MNIST dataset"""

#Load the MNIST dataset using tensorflow.keras.datasets.
(X_train, y_train), (X_test, y_test) = mnist.load_data()

"""# Preprocess the data

**Normalize the pixel values to a [0,1] range.**
"""

#Preprocess the data
#Normarlive the pixel values to be in the range 0,1
X_train = X_train/255.0
X_test = X_test/255.0

"""**One-hot encode the labels using to_categorical.**"""

#Perform one-hot encoding on  categorical features
y_train_categ = to_categorical(y_train, num_classes=10)
y_test_categ = to_categorical(y_test, num_classes=10)

"""# Visualize at least 9 random images with their labels using matplotlib."""

#Visualize at least 9 random images with their labels using matplotlib.
#select 9 indices randomly  to plot
selected_indices = np.random.choice(len(X_train), size=9, replace=False)

#set the plot figure size
plt.figure(figsize=(6, 5))

#use for loop to iterate through the indeices
for i, idx in enumerate(selected_indices):
    plt.subplot(3, 3, i+1)
    plt.imshow(X_train[idx], cmap='gray')
    plt.title(f"Label: {y_train[idx]}")
    plt.axis('off')
plt.tight_layout()
plt.show()

#Print dataset shapes and confirm correct preprocessing.
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

"""# Build the Artificial Neural Network Model (Sequential Model)"""

#Build the ANN using the sequential model
model = Sequential([
    #inlude the flattened layer as the input layer
    Flatten(input_shape=(28, 28)),

    #use the ReLU activation function
    #the first hidden later with 128 neurons
    Dense(128, activation='relu'),

    #specify the Dropout Layers at 0.3 for regularization
    Dropout(0.3),
    #the second hidden later with 64 neurons
    Dense(64, activation='relu'),
    #specify the Dropout Layers at 0.3 for regularization
    Dropout(0.3),

    #the output layer with 10 neurons for the 10 classes of the digits 0-9
    #and use the softmax activation function
    Dense(10, activation='softmax')
])

"""# Compile with adam optimizer and categorical_crossentropyloss."""

#Compile with adam optimizer and categorical_crossentropyloss.
model.compile(optimizer='adam', #use adam optimizer
              loss='categorical_crossentropy',
              #Use accuracy as the evaluation metric.
              metrics=['accuracy'])

"""# Train the mode"""

#Train the model for 10 epochs, using a batch_size of 128 and a validation_split of 0.1.
history = model.fit(X_train,
                    y_train_categ,
                    epochs=10,
                    batch_size=128,
                    validation_split=0.1)

"""# Evaluate the model"""

#Evaluate the model on the test set and report the final test accuracy.
test_loss, test_acc = model.evaluate(X_test, y_test_categ)
print(f'Test accuracy:\n {test_acc:.4f}')

"""# Plot training and validation accuracy/loss per epoch."""

#Plot training and validation accuracy/loss per epoch.
#Visualize the model training history
plt.figure(figsize=(6,4))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy',color="red", fontsize=14)
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""# Model Predictions"""

#Use model.predict() to get predictions on test data.
model_predictions = model.predict(X_test)
print(model_predictions)

"""# Display a confusion matrix

Display a confusion matrix using seaborn.heatmap.
"""

#Display a confusion matrix using seaborn.heatmap.
y_test_model_pred = model.predict(X_test)
y_pred_test= np.argmax(y_test_model_pred, axis=1)
y_test_labels = np.argmax(y_test_categ, axis=1)


#generate the confusion matrix heatmap in seaborn
cm = confusion_matrix(y_test_labels, y_pred_test)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=range(10),
            yticklabels=range(10))
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

"""# Print a classification report

Print a classification report showing precision, recall, and F1-score.
"""

#Print a classification report showing precision, recall, and F1-score.
print(classification_report(y_test_labels, y_pred_test))

"""# Save the trained model in the native Keras format"""

#Save the trained model in the native Keras format
model.save('mnist_model.h5')

#relaod the model
loaded_model = keras.models.load_model('mnist_model.h5')

# @title
#evaluate the  reloaded model
loaded_model.compile(optimizer='adam', #use adam optimizer
              loss='categorical_crossentropy',
              #Use accuracy as the evaluation metric.
              metrics=['accuracy'])
loaded_model.evaluate(X_test, y_test_categ)